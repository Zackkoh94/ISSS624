[
  {
    "objectID": "Take-home_Ex1/Take-home_Ex1.html",
    "href": "Take-home_Ex1/Take-home_Ex1.html",
    "title": "Take-home_Ex1",
    "section": "",
    "text": "As urban infrastructures become increasingly digitized, data from sources like buses, taxis, and public utilities offer valuable insights into movement patterns over time and space. The widespread use of technologies like GPS and RFID in vehicles has generated massive datasets, including route and ridership data. Analyzing these datasets can reveal important patterns and characteristics of human movement in a city, benefiting urban management and transport service providers.\nThis study aims to leverage Exploratory Spatial Data Analysis (ESDA), specifically Local Indicators of Spatial Association (LISA) and Emerging Hot Spot Analysis (EHSA), to uncover spatial and spatio-temporal mobility patterns among public bus passengers in Singapore.\n\n\nThe R packages used for the analysis are as follows:\n\nsf: Analyzes and models spatial dependencies in data.\ntmap: Creates thematic maps for visualizing geospatial data.\ntidyverse: A collection of R packages with a unified approach for data manipulation and visualization.\nplotly: Enables interactive and dynamic data visualizations.\nzoo: Handles and analyzes time series data.\nKendall: Computes Kendall’s tau rank correlation coefficient for assessing rank-based associations.\nkableExtra: Enhances ‘knitr’ package’s ‘kable()’ function for styling HTML and LaTeX tables in R Markdown. It offers advanced formatting options like row/column customization, conditional styling, and captioning, elevating tables to publication quality.\nggrain: R-package that allows you to create Raincloud plots - following the ‘Grammar of Graphics’ (i.e., ggplot2)\nDT: Create interactive html tables\n\n\n\nCode\npacman::p_load(sf, sfdep, tmap, tidyverse, plotly, zoo, Kendall, kableExtra, ggrain, DT)\n\n\n\n\n\n\n\n\n\n\n\n\n\nImport BusOD\n\n\n\n\n\n\n\nCode\n# Load each csv file into R separately\nbus08 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202308.csv\")\nbus09 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202309.csv\")\nbus10 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202310.csv\")\n\n# Combine all rows into single dataframe\norigind &lt;- rbind(bus08, bus09, bus10)\n\nstr(origind)\n\n\nspc_tbl_ [17,118,005 × 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ YEAR_MONTH         : chr [1:17118005] \"2023-08\" \"2023-08\" \"2023-08\" \"2023-08\" ...\n $ DAY_TYPE           : chr [1:17118005] \"WEEKDAY\" \"WEEKENDS/HOLIDAY\" \"WEEKENDS/HOLIDAY\" \"WEEKDAY\" ...\n $ TIME_PER_HOUR      : num [1:17118005] 16 16 14 14 17 17 17 17 7 17 ...\n $ PT_TYPE            : chr [1:17118005] \"BUS\" \"BUS\" \"BUS\" \"BUS\" ...\n $ ORIGIN_PT_CODE     : chr [1:17118005] \"04168\" \"04168\" \"80119\" \"80119\" ...\n $ DESTINATION_PT_CODE: chr [1:17118005] \"10051\" \"10051\" \"90079\" \"90079\" ...\n $ TOTAL_TRIPS        : num [1:17118005] 7 2 3 10 5 4 3 22 3 3 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   YEAR_MONTH = col_character(),\n  ..   DAY_TYPE = col_character(),\n  ..   TIME_PER_HOUR = col_double(),\n  ..   PT_TYPE = col_character(),\n  ..   ORIGIN_PT_CODE = col_character(),\n  ..   DESTINATION_PT_CODE = col_character(),\n  ..   TOTAL_TRIPS = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\n\n\n\n\n\n\n\n\nVariables\n\n\n\n\n\n\n\nCode\nhead(origind,10) %&gt;%\n  kbl() %&gt;%\n  kable_styling(\n    full_width = F, \n    bootstrap_options = c(\"condensed\", \"responsive\"))\n\n\n\n\n\n\nYEAR_MONTH\nDAY_TYPE\nTIME_PER_HOUR\nPT_TYPE\nORIGIN_PT_CODE\nDESTINATION_PT_CODE\nTOTAL_TRIPS\n\n\n\n\n2023-08\nWEEKDAY\n16\nBUS\n04168\n10051\n7\n\n\n2023-08\nWEEKENDS/HOLIDAY\n16\nBUS\n04168\n10051\n2\n\n\n2023-08\nWEEKENDS/HOLIDAY\n14\nBUS\n80119\n90079\n3\n\n\n2023-08\nWEEKDAY\n14\nBUS\n80119\n90079\n10\n\n\n2023-08\nWEEKENDS/HOLIDAY\n17\nBUS\n44069\n17229\n5\n\n\n2023-08\nWEEKDAY\n17\nBUS\n44069\n17229\n4\n\n\n2023-08\nWEEKENDS/HOLIDAY\n17\nBUS\n20281\n20141\n3\n\n\n2023-08\nWEEKDAY\n17\nBUS\n20281\n20141\n22\n\n\n2023-08\nWEEKDAY\n7\nBUS\n19051\n10017\n3\n\n\n2023-08\nWEEKENDS/HOLIDAY\n17\nBUS\n11169\n04219\n3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariables Description\n\n\n\n\n\n\nYEAR_MONTH: Data collection month in the format of YYYY-MM.\nDAY_TYPE: Weekday or Weekends/Holiday.\nTIME_PER_HOUR: Hour of the day in 24 hour format.\nPT_TYPE: Type of public transportation.\nORIGIN_PT_CODE: Identifier for the bus stop where the trip originated.\nDESTINATION_PT_CODE: Identifier for the bus stop where the trip ended.\nTOTAL_TRIPS: Total number of trips recorded for each origin-destination pair.\n\n\n\n\n\n\n\n\n\n\nSummary Statistics and EDA\n\n\n\n\n\n\n\nCode\nsummary(origind)\n\n\n  YEAR_MONTH          DAY_TYPE         TIME_PER_HOUR     PT_TYPE         \n Length:17118005    Length:17118005    Min.   : 0.00   Length:17118005   \n Class :character   Class :character   1st Qu.:10.00   Class :character  \n Mode  :character   Mode  :character   Median :14.00   Mode  :character  \n                                       Mean   :14.06                     \n                                       3rd Qu.:18.00                     \n                                       Max.   :23.00                     \n ORIGIN_PT_CODE     DESTINATION_PT_CODE  TOTAL_TRIPS      \n Length:17118005    Length:17118005     Min.   :    1.00  \n Class :character   Class :character    1st Qu.:    2.00  \n Mode  :character   Mode  :character    Median :    4.00  \n                                        Mean   :   20.46  \n                                        3rd Qu.:   12.00  \n                                        Max.   :36668.00  \n\n\n\n\nCode\n# Count unique values in ORIGIN_PT_CODE\nunique_origin_count &lt;- n_distinct(origind$ORIGIN_PT_CODE)\n\n# Count unique values in DESTINATION_PT_CODE\nunique_destination_count &lt;- n_distinct(origind$DESTINATION_PT_CODE)\n\n# Print the counts\nprint(paste(\"Unique origins:\", unique_origin_count))\n\n\n[1] \"Unique origins: 5075\"\n\n\nCode\nprint(paste(\"Unique destinations:\", unique_destination_count))\n\n\n[1] \"Unique destinations: 5079\"\n\n\n\n\nCode\n# Calculate the mean of TOTAL_TRIPS\nmean_total_trips &lt;- median(origind$TOTAL_TRIPS)\n\n# Count the number of rows where TOTAL_TRIPS is above the mean\nrows_above_mean &lt;- sum(origind$TOTAL_TRIPS &gt; mean_total_trips)\n\n# Print the count\nprint(rows_above_mean)\n\n\n[1] 7977626\n\n\n\n\nMost of the data types have a Class and Mode of “character”\nOver a three-month period, a total of 17,118,005 combinations of bus trips were recorded.\nThere are 5075 unique origin bus stops, and 5079 unique destination bus stops\nOn average, there are 20.46 trips for each bus route, but the highest recorded number of trips for a single route is an exceptional 36,668. This significant discrepancy suggests there might be outliers or anomalies in the data, warranting additional investigation.\nIn a dataset of 17 million trips, the low median of 4, high mean of 20.5, and a maximum of 38,000, along with over 7.9 million trips exceeding the median, indicate a right-skewed distribution. This suggests a concentration of lower-value trips with numerous higher-value outliers.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImport BusStop\n\n\n\n\n\n\n\nCode\nbusstop &lt;- st_read(\n    dsn = \"data/geospatial\",\n    layer = \"BusStop\"\n  ) %&gt;%\n  mutate(\n    BUS_STOP_N = as.factor(BUS_STOP_N),\n    BUS_ROOF_N = as.factor(BUS_ROOF_N),\n    LOC_DESC = as.factor(LOC_DESC)\n  )\n\n\nReading layer `BusStop' from data source \n  `C:\\Zackkoh94\\ISSS624\\Take-home_Ex1\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\nCode\nglimpse(busstop)\n\n\nRows: 5,161\nColumns: 4\n$ BUS_STOP_N &lt;fct&gt; 22069, 32071, 44331, 96081, 11561, 66191, 23389, 54411, 285…\n$ BUS_ROOF_N &lt;fct&gt; B06, B23, B01, B05, B05, B03, B02A, B02, B09, B01, B16, B02…\n$ LOC_DESC   &lt;fct&gt; OPP CEVA LOGISTICS, AFT TRACK 13, BLK 239, GRACE INDEPENDEN…\n$ geometry   &lt;POINT [m]&gt; POINT (13576.31 32883.65), POINT (13228.59 44206.38),…\n\n\n\n\n\n\n\n\n\n\n\nCoordinate reference system\n\n\n\n\n\n\n\nCode\nst_crs(busstop)\n\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"WGS 84\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nThe EPSG.io database indicates that the coordinate system for Singapore is SVY21, associated with the EPSG code 3414. However, the ‘busstop’ dataset is currently projected using SVY21 with an EPSG code of 9001, highlighting a need to change to correct it to the EPSG code of 3414.\n\n\nCode\n# Setting the CRS for the busstop data to EPSG 3414\nbusstop &lt;- st_set_crs(busstop, 3414) %&gt;%\n  # Changing the column name for easier integration with main dataframe\n  mutate(\n    ORIGIN_PT_CODE = as.factor(BUS_STOP_N)\n  ) %&gt;%\n  # Keeping only necessary columns for further analysis\n  select(\n    ORIGIN_PT_CODE, \n    LOC_DESC,\n    geometry\n  )\n\n# Verifying the CRS assignment for busstop\nst_crs(busstop)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Take-home_Ex1/Take-home_Ex1.html#overview",
    "href": "Take-home_Ex1/Take-home_Ex1.html#overview",
    "title": "Take-home_Ex1",
    "section": "",
    "text": "As urban infrastructures become increasingly digitized, data from sources like buses, taxis, and public utilities offer valuable insights into movement patterns over time and space. The widespread use of technologies like GPS and RFID in vehicles has generated massive datasets, including route and ridership data. Analyzing these datasets can reveal important patterns and characteristics of human movement in a city, benefiting urban management and transport service providers.\nThis study aims to leverage Exploratory Spatial Data Analysis (ESDA), specifically Local Indicators of Spatial Association (LISA) and Emerging Hot Spot Analysis (EHSA), to uncover spatial and spatio-temporal mobility patterns among public bus passengers in Singapore.\n\n\nThe R packages used for the analysis are as follows:\n\nsf: Analyzes and models spatial dependencies in data.\ntmap: Creates thematic maps for visualizing geospatial data.\ntidyverse: A collection of R packages with a unified approach for data manipulation and visualization.\nplotly: Enables interactive and dynamic data visualizations.\nzoo: Handles and analyzes time series data.\nKendall: Computes Kendall’s tau rank correlation coefficient for assessing rank-based associations.\nkableExtra: Enhances ‘knitr’ package’s ‘kable()’ function for styling HTML and LaTeX tables in R Markdown. It offers advanced formatting options like row/column customization, conditional styling, and captioning, elevating tables to publication quality.\nggrain: R-package that allows you to create Raincloud plots - following the ‘Grammar of Graphics’ (i.e., ggplot2)\nDT: Create interactive html tables\n\n\n\nCode\npacman::p_load(sf, sfdep, tmap, tidyverse, plotly, zoo, Kendall, kableExtra, ggrain, DT)\n\n\n\n\n\n\n\n\n\n\n\n\n\nImport BusOD\n\n\n\n\n\n\n\nCode\n# Load each csv file into R separately\nbus08 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202308.csv\")\nbus09 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202309.csv\")\nbus10 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202310.csv\")\n\n# Combine all rows into single dataframe\norigind &lt;- rbind(bus08, bus09, bus10)\n\nstr(origind)\n\n\nspc_tbl_ [17,118,005 × 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ YEAR_MONTH         : chr [1:17118005] \"2023-08\" \"2023-08\" \"2023-08\" \"2023-08\" ...\n $ DAY_TYPE           : chr [1:17118005] \"WEEKDAY\" \"WEEKENDS/HOLIDAY\" \"WEEKENDS/HOLIDAY\" \"WEEKDAY\" ...\n $ TIME_PER_HOUR      : num [1:17118005] 16 16 14 14 17 17 17 17 7 17 ...\n $ PT_TYPE            : chr [1:17118005] \"BUS\" \"BUS\" \"BUS\" \"BUS\" ...\n $ ORIGIN_PT_CODE     : chr [1:17118005] \"04168\" \"04168\" \"80119\" \"80119\" ...\n $ DESTINATION_PT_CODE: chr [1:17118005] \"10051\" \"10051\" \"90079\" \"90079\" ...\n $ TOTAL_TRIPS        : num [1:17118005] 7 2 3 10 5 4 3 22 3 3 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   YEAR_MONTH = col_character(),\n  ..   DAY_TYPE = col_character(),\n  ..   TIME_PER_HOUR = col_double(),\n  ..   PT_TYPE = col_character(),\n  ..   ORIGIN_PT_CODE = col_character(),\n  ..   DESTINATION_PT_CODE = col_character(),\n  ..   TOTAL_TRIPS = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\n\n\n\n\n\n\n\n\nVariables\n\n\n\n\n\n\n\nCode\nhead(origind,10) %&gt;%\n  kbl() %&gt;%\n  kable_styling(\n    full_width = F, \n    bootstrap_options = c(\"condensed\", \"responsive\"))\n\n\n\n\n\n\nYEAR_MONTH\nDAY_TYPE\nTIME_PER_HOUR\nPT_TYPE\nORIGIN_PT_CODE\nDESTINATION_PT_CODE\nTOTAL_TRIPS\n\n\n\n\n2023-08\nWEEKDAY\n16\nBUS\n04168\n10051\n7\n\n\n2023-08\nWEEKENDS/HOLIDAY\n16\nBUS\n04168\n10051\n2\n\n\n2023-08\nWEEKENDS/HOLIDAY\n14\nBUS\n80119\n90079\n3\n\n\n2023-08\nWEEKDAY\n14\nBUS\n80119\n90079\n10\n\n\n2023-08\nWEEKENDS/HOLIDAY\n17\nBUS\n44069\n17229\n5\n\n\n2023-08\nWEEKDAY\n17\nBUS\n44069\n17229\n4\n\n\n2023-08\nWEEKENDS/HOLIDAY\n17\nBUS\n20281\n20141\n3\n\n\n2023-08\nWEEKDAY\n17\nBUS\n20281\n20141\n22\n\n\n2023-08\nWEEKDAY\n7\nBUS\n19051\n10017\n3\n\n\n2023-08\nWEEKENDS/HOLIDAY\n17\nBUS\n11169\n04219\n3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariables Description\n\n\n\n\n\n\nYEAR_MONTH: Data collection month in the format of YYYY-MM.\nDAY_TYPE: Weekday or Weekends/Holiday.\nTIME_PER_HOUR: Hour of the day in 24 hour format.\nPT_TYPE: Type of public transportation.\nORIGIN_PT_CODE: Identifier for the bus stop where the trip originated.\nDESTINATION_PT_CODE: Identifier for the bus stop where the trip ended.\nTOTAL_TRIPS: Total number of trips recorded for each origin-destination pair.\n\n\n\n\n\n\n\n\n\n\nSummary Statistics and EDA\n\n\n\n\n\n\n\nCode\nsummary(origind)\n\n\n  YEAR_MONTH          DAY_TYPE         TIME_PER_HOUR     PT_TYPE         \n Length:17118005    Length:17118005    Min.   : 0.00   Length:17118005   \n Class :character   Class :character   1st Qu.:10.00   Class :character  \n Mode  :character   Mode  :character   Median :14.00   Mode  :character  \n                                       Mean   :14.06                     \n                                       3rd Qu.:18.00                     \n                                       Max.   :23.00                     \n ORIGIN_PT_CODE     DESTINATION_PT_CODE  TOTAL_TRIPS      \n Length:17118005    Length:17118005     Min.   :    1.00  \n Class :character   Class :character    1st Qu.:    2.00  \n Mode  :character   Mode  :character    Median :    4.00  \n                                        Mean   :   20.46  \n                                        3rd Qu.:   12.00  \n                                        Max.   :36668.00  \n\n\n\n\nCode\n# Count unique values in ORIGIN_PT_CODE\nunique_origin_count &lt;- n_distinct(origind$ORIGIN_PT_CODE)\n\n# Count unique values in DESTINATION_PT_CODE\nunique_destination_count &lt;- n_distinct(origind$DESTINATION_PT_CODE)\n\n# Print the counts\nprint(paste(\"Unique origins:\", unique_origin_count))\n\n\n[1] \"Unique origins: 5075\"\n\n\nCode\nprint(paste(\"Unique destinations:\", unique_destination_count))\n\n\n[1] \"Unique destinations: 5079\"\n\n\n\n\nCode\n# Calculate the mean of TOTAL_TRIPS\nmean_total_trips &lt;- median(origind$TOTAL_TRIPS)\n\n# Count the number of rows where TOTAL_TRIPS is above the mean\nrows_above_mean &lt;- sum(origind$TOTAL_TRIPS &gt; mean_total_trips)\n\n# Print the count\nprint(rows_above_mean)\n\n\n[1] 7977626\n\n\n\n\nMost of the data types have a Class and Mode of “character”\nOver a three-month period, a total of 17,118,005 combinations of bus trips were recorded.\nThere are 5075 unique origin bus stops, and 5079 unique destination bus stops\nOn average, there are 20.46 trips for each bus route, but the highest recorded number of trips for a single route is an exceptional 36,668. This significant discrepancy suggests there might be outliers or anomalies in the data, warranting additional investigation.\nIn a dataset of 17 million trips, the low median of 4, high mean of 20.5, and a maximum of 38,000, along with over 7.9 million trips exceeding the median, indicate a right-skewed distribution. This suggests a concentration of lower-value trips with numerous higher-value outliers.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImport BusStop\n\n\n\n\n\n\n\nCode\nbusstop &lt;- st_read(\n    dsn = \"data/geospatial\",\n    layer = \"BusStop\"\n  ) %&gt;%\n  mutate(\n    BUS_STOP_N = as.factor(BUS_STOP_N),\n    BUS_ROOF_N = as.factor(BUS_ROOF_N),\n    LOC_DESC = as.factor(LOC_DESC)\n  )\n\n\nReading layer `BusStop' from data source \n  `C:\\Zackkoh94\\ISSS624\\Take-home_Ex1\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\nCode\nglimpse(busstop)\n\n\nRows: 5,161\nColumns: 4\n$ BUS_STOP_N &lt;fct&gt; 22069, 32071, 44331, 96081, 11561, 66191, 23389, 54411, 285…\n$ BUS_ROOF_N &lt;fct&gt; B06, B23, B01, B05, B05, B03, B02A, B02, B09, B01, B16, B02…\n$ LOC_DESC   &lt;fct&gt; OPP CEVA LOGISTICS, AFT TRACK 13, BLK 239, GRACE INDEPENDEN…\n$ geometry   &lt;POINT [m]&gt; POINT (13576.31 32883.65), POINT (13228.59 44206.38),…\n\n\n\n\n\n\n\n\n\n\n\nCoordinate reference system\n\n\n\n\n\n\n\nCode\nst_crs(busstop)\n\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"WGS 84\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nThe EPSG.io database indicates that the coordinate system for Singapore is SVY21, associated with the EPSG code 3414. However, the ‘busstop’ dataset is currently projected using SVY21 with an EPSG code of 9001, highlighting a need to change to correct it to the EPSG code of 3414.\n\n\nCode\n# Setting the CRS for the busstop data to EPSG 3414\nbusstop &lt;- st_set_crs(busstop, 3414) %&gt;%\n  # Changing the column name for easier integration with main dataframe\n  mutate(\n    ORIGIN_PT_CODE = as.factor(BUS_STOP_N)\n  ) %&gt;%\n  # Keeping only necessary columns for further analysis\n  select(\n    ORIGIN_PT_CODE, \n    LOC_DESC,\n    geometry\n  )\n\n# Verifying the CRS assignment for busstop\nst_crs(busstop)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Take-home_Ex1/Take-home_Ex1.html#data-preparation",
    "href": "Take-home_Ex1/Take-home_Ex1.html#data-preparation",
    "title": "Take-home_Ex1",
    "section": "2 Data Preparation",
    "text": "2 Data Preparation\n\n2.1 Aspatial Data\nThe task specified in this particular project requires the computation of passenger trips at the following specific timeframes.\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\n\n2.1.1 Data Type Edit2.1.2 Categorizing DataPreview\n\n\n\n\nCode\norigind &lt;- origind %&gt;%\n  mutate(\n    ORIGIN_PT_CODE = as.factor(ORIGIN_PT_CODE),\n    DESTINATION_PT_CODE = as.factor(DESTINATION_PT_CODE)\n  )\n\n\n\nAs mentioned before, ORIGIN_PT_CODE and DESTINATION_PT_CODE’s data type are in character format. Because they represent busstop locations, they should be transformed into factors (categorical data type) for further analysis\n\n\n\n\n\nCode\norigind_agg &lt;- origind %&gt;%\n  # Classify trips into specific time periods based on day type and hour\n  mutate(period = ifelse(DAY_TYPE == \"WEEKDAY\" & \n                         TIME_PER_HOUR &gt;= 6 & TIME_PER_HOUR &lt;= 9, \n                         \"Weekday morning peak\",\n                    ifelse(DAY_TYPE == \"WEEKDAY\" & \n                           TIME_PER_HOUR &gt;= 17 & TIME_PER_HOUR &lt;= 20,\n                           \"Weekday evening peak\",\n                      ifelse(DAY_TYPE == \"WEEKENDS/HOLIDAY\" &\n                             TIME_PER_HOUR &gt;= 11 & TIME_PER_HOUR &lt;= 14,\n                              \"Weekend/PH morning peak\",\n                        ifelse(DAY_TYPE == \"WEEKENDS/HOLIDAY\" & \n                              TIME_PER_HOUR &gt;= 16 & TIME_PER_HOUR &lt;= 19,\n                               \"Weekend/PH evening peak\",\n                    \"Others\"))))\n  ) %&gt;%\n  # Exclude data outside the specified periods for focused analysis\n  filter(\n    period != \"Others\"\n  ) %&gt;%\n  # Aggregate the total number of trips by origin bus stop and month for each classified period\n  group_by(\n    YEAR_MONTH,\n    period,\n    ORIGIN_PT_CODE\n  ) %&gt;%\n  summarise(\n    num_trips = sum(TOTAL_TRIPS)\n  ) %&gt;%\n  ungroup()\n\n\n\nWe categorize and preprocess the data into the time frames as shown above\n\n\n\n\n\nCode\nlist(origind_agg)\n\n\n[[1]]\n# A tibble: 60,168 × 4\n   YEAR_MONTH period               ORIGIN_PT_CODE num_trips\n   &lt;chr&gt;      &lt;chr&gt;                &lt;fct&gt;              &lt;dbl&gt;\n 1 2023-08    Weekday evening peak 01012               8448\n 2 2023-08    Weekday evening peak 01013               7328\n 3 2023-08    Weekday evening peak 01019               3608\n 4 2023-08    Weekday evening peak 01029               9317\n 5 2023-08    Weekday evening peak 01039              12937\n 6 2023-08    Weekday evening peak 01059               2133\n 7 2023-08    Weekday evening peak 01109                322\n 8 2023-08    Weekday evening peak 01112              45010\n 9 2023-08    Weekday evening peak 01113              27233\n10 2023-08    Weekday evening peak 01119               9323\n# ℹ 60,158 more rows\n\n\n\n\n\n\n\n2.2 Data Checks and wrangling\n\n2.2.1 Aspatial Check for duplicates2.2.2 Aspatial Check for Null\n\n\n\n\nCode\n# Count of dupes\ncount_duplicate_rows &lt;- function(df, df_name) {\n  df %&gt;%\n    group_by_all() %&gt;%\n    filter(n() &gt; 1) %&gt;%\n    ungroup() %&gt;%\n    summarise(df_name = df_name, row_count = n())\n}\n\nduplicate1 &lt;- count_duplicate_rows(bus08, \"bus08\")\nduplicate2 &lt;- count_duplicate_rows(bus09, \"bus09\")\nduplicate3 &lt;- count_duplicate_rows(bus10, \"bus10\")\n\nall_duplicates &lt;- bind_rows(duplicate1, duplicate2, duplicate3)\n\n# Output the combined counts\nprint(all_duplicates)\n\n\n# A tibble: 3 × 2\n  df_name row_count\n  &lt;chr&gt;       &lt;int&gt;\n1 bus08           0\n2 bus09           0\n3 bus10           0\n\n\n\nThere no duplicates which could adversely impact any join functions in the latter part of the project\n\n\n\n\n\nCode\n# Function to count the number of rows containing null values\ncount_null_rows &lt;- function(df, df_name) {\n  df %&gt;%\n    filter(if_any(everything(), is.na)) %&gt;%\n    summarise(df_name = df_name, row_count = n())\n}\n\n# Apply the function to each dataframe to count rows with nulls\nnulls1 &lt;- count_null_rows(bus08, \"bus08\")\nnulls2 &lt;- count_null_rows(bus09, \"bus09\")\nnulls3 &lt;- count_null_rows(bus10, \"bus10\")\n\n# Combine the results\nall_nulls &lt;- bind_rows(nulls1, nulls2, nulls3)\n\n# Print the counts of rows with nulls\nprint(all_nulls)\n\n\n# A tibble: 3 × 2\n  df_name row_count\n  &lt;chr&gt;       &lt;int&gt;\n1 bus08           0\n2 bus09           0\n3 bus10           0\n\n\n\nThere no nulls which could adversely impact any join functions in the latter part of the project"
  },
  {
    "objectID": "Take-home_Ex1/Take-home_Ex1.html#data-exploration",
    "href": "Take-home_Ex1/Take-home_Ex1.html#data-exploration",
    "title": "Take-home_Ex1",
    "section": "3 Data Exploration",
    "text": "3 Data Exploration\nUnderstanding daily passenger trip distribution is crucial for urban traffic management and congestion relief, with geospatial analysis providing insights into areas of dense commuter traffic and patterns.\nAs a start, we will look at the distribution of passenger trips for different periods in September 2023\n\n\nCode\n# Generate scatter plots for September 2023 bus passenger data\nbus09_scatter &lt;- origind_agg %&gt;%\n  filter(YEAR_MONTH == \"2023-09\") %&gt;%  # Focus on September 2023\n  ggplot(aes(x = num_trips, y = period, fill = period, color = period)) +  # Set plot aesthetics\n  geom_point(size = 3, alpha = 0.7) +  # Create scatter plot\n  scale_x_continuous(  # Configure x-axis scale\n    labels = scales::number_format(accuracy = 1), \n    breaks = scales::pretty_breaks(n = 5)) +\n  scale_fill_brewer(palette = \"Set2\") +  # Use a Brewer color palette\n  labs(\n    title = \"September 2023: Peak Passenger Volumes in Weekday Mornings\",\n    subtitle = \"Variability during weekdays suggests potential congestion\") + \n  theme(\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.text.x = element_blank()  # Remove x-axis labels for clarity\n  )  # Adjust plot theme for a clean appearance\n\n# Display the plot\nbus09_scatter\n\n\n\n\n\n\nPassenger counts are notably higher during peak weekday hours as opposed to weekend or public holiday peaks.\nEach peak hour time frame exhibits a distribution skewed toward higher values (right), indicating sporadic instances of unusually high passenger numbers.\nSuch patterns may point to congestion at the Central Business District (CBD), bus stops near the highways, where passengers frequent to change buses, or Bus interchanges.\nSubsequent investigation could ascertain if these occurrences are geographically clustered, helping to identify probable congestion focal points.\n\nNext we explore if the distribution changes across different months (i.e. August to October 2023)\n\n\nCode\n# Generate scatter plots for bus passenger data\norigind_scatter &lt;- origind_agg %&gt;%\n  ggplot(aes(x = period, y = num_trips, fill = period, color = period)) +\n  geom_violin(position = position_nudge(x = 0, y = .2), alpha = 0.5) +  # Create violin plots\n  geom_point(aes(y = num_trips, color = period), \n             position = position_jitter(height = .15), size = .5, alpha = 0.8) +  # Add jittered points\n  facet_wrap(~YEAR_MONTH, nrow = 1) +  # Facet by YEAR_MONTH for comparison\n  scale_y_continuous(labels = scales::number_format(accuracy = 1), \n                     breaks = scales::pretty_breaks(n = 3)) +  # Adjust y-axis scale\n  labs(title = \"Passenger Volume Distribution: Aug - Oct 2023\") +  # Add a descriptive title\n  theme(\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.ticks.x = element_blank(),\n    axis.text.x = element_blank()  # Remove x-axis labels for clarity\n  )  \n\n# Display the plot\norigind_scatter\n\n\n\n\n\nThe scatter plots indicate a consistent trip distribution across three months, suggesting the presence of bus stops with high passenger volumes, particularly during weekday evenings. This consistency hints at potential congestion hot spots, particularly if these stops are clustered. Consequently, focused Geospatial analysis on September 2023 data will be used to identify these areas."
  },
  {
    "objectID": "Take-home_Ex1/Take-home_Ex1.html#spatial-polygon-preparation",
    "href": "Take-home_Ex1/Take-home_Ex1.html#spatial-polygon-preparation",
    "title": "Take-home_Ex1",
    "section": "4 Spatial Polygon preparation",
    "text": "4 Spatial Polygon preparation\n\n4.1 Month- Data Extraction\nextract September 2023 data\n\n\nCode\n# Isolate September 2023 data for focused analysis\norigind09 &lt;- origind_agg %&gt;%\n  filter(YEAR_MONTH == \"2023-09\") %&gt;%  # Targeting September 2023\n  pivot_wider(  # Transform data to wide format for easier analysis\n    names_from = period,\n    values_from = num_trips\n  ) %&gt;%\n  select(-YEAR_MONTH)  # Exclude YEAR_MONTH column from the final output\n\n# Create a datatable visualization for the transformed data\nDT::datatable(origind09,\n              options = list(pageLength = 5, autoWidth = TRUE),\n              rownames = FALSE)  # Configure table display options\n\n\n\n\n\n\n\n\n\n4.2 Left Join to create dataframe\n\n\nCode\norigind09_sf &lt;- left_join(busstop, origind09, by = \"ORIGIN_PT_CODE\")\n\norigind09_sf\n\n\nSimple feature collection with 5161 features and 6 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   ORIGIN_PT_CODE             LOC_DESC Weekday evening peak\n1           22069   OPP CEVA LOGISTICS                   44\n2           32071         AFT TRACK 13                   NA\n3           44331              BLK 239                 1524\n4           96081 GRACE INDEPENDENT CH                  274\n5           11561              BLK 166                  134\n6           66191         AFT CORFE PL                  325\n7           23389              PEC LTD                  388\n8           54411              BLK 527                 1204\n9           28531              BLK 536                 3529\n10          96139              BLK 148                 1152\n   Weekday morning peak Weekend/PH evening peak Weekend/PH morning peak\n1                    13                       2                      20\n2                    NA                       1                      NA\n3                  1701                     630                     707\n4                   286                      99                     114\n5                   152                      79                      77\n6                   386                     193                     234\n7                    49                      81                      18\n8                  2764                     649                    1612\n9                  8000                    2222                    2373\n10                 4406                     735                     997\n                    geometry\n1  POINT (13576.31 32883.65)\n2  POINT (13228.59 44206.38)\n3   POINT (21045.1 40242.08)\n4  POINT (41603.76 35413.11)\n5  POINT (24568.74 30391.85)\n6  POINT (30951.58 38079.61)\n7    POINT (12476.9 32211.6)\n8  POINT (30329.45 39373.92)\n9  POINT (14993.31 36905.61)\n10  POINT (41642.81 36513.9)\n\n\n\n\n4.3 Creating Hexagon Spatial Grid\norigind09_sf , being a dataframe containing spatial points, isn’t ideal for spatial autocorrelation studies that necessitate ‘areas’ to be depicted as polygons. The code that follows will reorganize these bus stop points into a hexagonal lattice for better spatial analysis.\n\n\nCode\norigind09_hx &lt;- st_make_grid(\n    origind09_sf,\n    cellsize = 500,\n    square = FALSE\n  ) %&gt;%\n  st_sf() %&gt;%\n  rowid_to_column(\"hex_id\")\n\n\nThe code above does the following:\n\nThe cellsize parameter is measured in the same units as the origind09_sf dataframe’s coordinate system. Since origind09_sf uses EPSG:3414 projection, which has units in meters, this cellsize defines the hexagon’s width, here chosen to be 500 meters.\nEach hexagon is given a unique hex_id as the primary key.\n\n\n\n4.4 Generate Attribute Dataframe using Hexagon Identifiers\nThe hexagonal grid is designed to contain multiple bus stops, with each hexagon’s hex_id acting as the key for compiling data. The following steps detail the process for structuring attributes based on hex_id:\n\nApply st_join() with the st_within join condition to match bus stop points to their respective hexagons.\nUse st_set_geometry(NULL) to remove the spatial aspect, shifting the focus to attribute consolidation.\nImplement group_by() to consolidate data under a distinct hex_id.\nDeploy summarise() to tally the number of bus stops and to sum up trips for each peak period by hexagon.\nConvert any NA entries to 0 with replace(is.na(.), 0) to clean the dataset. #This is just a precaution although we already did the checks prior\n\n\n\nCode\n# Joining bus stops with hexagonal areas and summarizing data\norigind09_stops &lt;- origind09_sf %&gt;%\n  st_join(origind09_hx, join = st_within) %&gt;%  # Associate bus stops with hexagons\n  group_by(hex_id) %&gt;%  # Group by hexagon ID\n  summarise(\n    total_busstops = n(),  # Count bus stops per hexagon\n    busstop_ids = str_c(ORIGIN_PT_CODE, collapse = \", \"),  # Combine bus stop codes\n        loc_descriptions = str_c(LOC_DESC, collapse = \"; \"),  # Combine location descriptions\n    peak_weekday_morning = sum(`Weekday morning peak`),  # Sum for weekday morning peak\n    peak_weekday_evening = sum(`Weekday evening peak`),  # Sum for weekday evening peak\n    peak_weekend_morning = sum(`Weekend/PH morning peak`),  # Sum for weekend morning peak\n    peak_weekend_evening = sum(`Weekend/PH evening peak`)   # Sum for weekend evening peak\n  ) %&gt;%\n  st_set_geometry(NULL) %&gt;%  # Remove spatial component\n  replace_na(list(peak_weekday_morning = 0, peak_weekday_evening = 0,  # Replace NA with 0\n                  peak_weekend_morning = 0, peak_weekend_evening = 0)) %&gt;%\n  ungroup()  # Remove grouping\n\n# Display the processed data\norigind09_stops\n\n\n# A tibble: 1,524 × 8\n   hex_id total_busstops busstop_ids  loc_descriptions      peak_weekday_morning\n    &lt;int&gt;          &lt;int&gt; &lt;chr&gt;        &lt;chr&gt;                                &lt;dbl&gt;\n 1     34              1 25059        AFT TUAS STH BLVD                       91\n 2     65              1 25751        BEF TUAS STH AVE 14                     41\n 3     99              1 26379        YONG NAM                                50\n 4    127              1 25761        OPP REC S'PORE                         129\n 5    129              2 25719, 26389 THE INDEX; BEF TUAS …                 1104\n 6    130              1 26369        SEE HUP SENG                            34\n 7    131              1 26299        BEF TUAS STH AVE 6                      41\n 8    159              1 25741        HALLIBURTON                             66\n 9    160              1 25711        OPP THE INDEX                          204\n10    161              2 25701, 25709 GLAXOSMITHKLINE; EDG…                  842\n# ℹ 1,514 more rows\n# ℹ 3 more variables: peak_weekday_evening &lt;dbl&gt;, peak_weekend_morning &lt;dbl&gt;,\n#   peak_weekend_evening &lt;dbl&gt;\n\n\n\n\n4.5 Create Spatial Polygon dataframe\n\n\nCode\norigind09_hx &lt;- origind09_hx %&gt;%\n  left_join(origind09_stops,\n            by = \"hex_id\"\n  ) %&gt;%\n  replace(is.na(.), 0)\n\nbus_traffic_09 &lt;- filter(origind09_hx,\n                       total_busstops &gt; 0)"
  },
  {
    "objectID": "Take-home_Ex1/Take-home_Ex1.html#visualization-and-sense-making",
    "href": "Take-home_Ex1/Take-home_Ex1.html#visualization-and-sense-making",
    "title": "Take-home_Ex1",
    "section": "5 5.0 Visualization and Sense Making",
    "text": "5 5.0 Visualization and Sense Making\nThis sections aims to conduct visualization and sense making of the current data before embarking on more complex methodologies such as Local Indicators of Spatial Association (LISA)\n\n\nCode\n# Switch to tmap interactive viewing mode\ntmap_mode(\"plot\")\n\n# Creating an interactive map of bus traffic\nbus_traffic_09_map &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(bus_traffic_09) +  # Connecting tm_shape directly to tm_fill\n  tm_fill(\n    col = \"total_busstops\",  # Color based on the number of bus stops\n    palette = \"YlGnBu\",  # Using the YlGnBu color palette\n    style = \"cont\",  # Continuous color style\n    id = \"loc_descriptions\",  # Identify hexagons by hex_id\n    popup.vars = c(\"Bus Stops Count\" = \"total_busstops\",\n                   \"Stop Codes\" = \"busstop_ids\"),  # Popup information\n    title = \"Number of Bus Stops\"  # Title for the color legend\n  ) +\n  tm_layout(\n    legend.show = TRUE)  \n\n# Display the interactive map\nbus_traffic_09_map\n\n\n\n\n\nThe map indicates that the central area, which likely includes the Business Districts, the likes of the Central Business districts or One North Business parks, as well as highly populated residential zones areas like Seng Kang, have a higher concentration of bus stops. These areas are known for their high human traffic which necessitates the need for a more conducive and extensive public transportation network to facilitate the daily travel needs of its patrons.\n\nIn contrast, the more unvisited areas of the island, such as Lim Chu Kang, an area marked for more agricultural activities, are marked by lighter shades, highlighting a sparser presence of bus stops.\nThese regions, which are less urbanized or more industrialized typically see lower human traffic.\n\nThe distribution of bus stops in Singapore as seen in the map emulates Singapore’s Land Transport Authority (LTA)’s strategic approach to provide an efficient bus serivice, focusing on providing efficient access and use of resources, as well as connectivity, especially in areas with high human traffic where public transport demand is higher.\n\n\n5.1 Peak Period Analysis\n\n\nCode\nsummary(origind09_sf)\n\n\n ORIGIN_PT_CODE                LOC_DESC    Weekday evening peak\n 11009  :   2   BLK 1              :   6   Min.   :     1      \n 22501  :   2   BLK 25             :   6   1st Qu.:   639      \n 43709  :   2   AFT YIO CHU KANG RD:   5   Median :  1797      \n 47201  :   2   BLK 101            :   5   Mean   :  4464      \n 51071  :   2   BLK 109            :   5   3rd Qu.:  4080      \n 52059  :   2   (Other)            :5126   Max.   :481495      \n (Other):5149   NA's               :   8   NA's   :170         \n Weekday morning peak Weekend/PH evening peak Weekend/PH morning peak\n Min.   :     1       Min.   :     1.0        Min.   :     1         \n 1st Qu.:   414       1st Qu.:   228.5        1st Qu.:   207         \n Median :  1946       Median :   715.0        Median :   742         \n Mean   :  4560       Mean   :  1707.7        Mean   :  1689         \n 3rd Qu.:  5430       3rd Qu.:  1666.0        3rd Qu.:  1889         \n Max.   :328545       Max.   :158693.0        Max.   :112330         \n NA's   :176          NA's   :202             NA's   :180            \n          geometry   \n POINT        :5161  \n epsg:3414    :   0  \n +proj=tmer...:   0  \n                     \n                     \n                     \n                     \n\n\nReinforcing the statements above, the summary has concluded that the data is indeed right skewed, as such the breaks for the following maps will be adjusted to better illustrate the comparisons between peak hour time frames\n\n\nCode\npeak_weekday_morning_map &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(bus_traffic_09) +\n  tm_fill(\n    col = \"peak_weekday_morning\",\n    palette = \"YlGnBu\",\n    title = \"Peak Weekday Morning Traffic\",\n    id = \"loc_descriptions\",\n    showNA = FALSE,\n    alpha = 0.6,\n    breaks = c(0, 500, 1000, 2000, 3000, 5000, 10000, 50000, 100000, 300000, 550000)\n  ) +\n  tm_borders() +\n  tm_layout(\n    legend.show = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    legend.width = 0.2,\n    legend.height = 0.5\n  )\n\npeak_weekday_morning_map\n\n\n\n\n\n\n\nCode\npeak_weekday_evening_map &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(bus_traffic_09) +\n  tm_fill(\n    col = \"peak_weekday_evening\",\n    palette = \"YlOrRd\",\n    title = \"Peak Weekday Evening Traffic\",\n    id = \"loc_descriptions\",\n    showNA = FALSE,\n    alpha = 0.6,\n    breaks = c(0, 500, 1000, 2000, 3000, 5000, 10000, 50000, 100000, 300000, 550000)\n  ) +\n  tm_borders() +\n  tm_layout(\n    legend.show = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    legend.width = 0.2,\n    legend.height = 0.5\n  )\n\npeak_weekday_evening_map\n\n\n\n\n\n\n\nCode\npeak_weekend_evening_map &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(bus_traffic_09) +  # Added '+' here\n  tm_fill(\n    col = \"peak_weekend_evening\",\n    palette = \"RdPu\",\n    title = \"Peak Weekend Evening Traffic\",\n    id = \"loc_descriptions\",\n    showNA = FALSE,\n    alpha = 0.6,\n    breaks = c(0, 500, 1000, 2000, 3000, 5000, 10000, 50000, 100000, 300000, 550000)\n  ) +\n  tm_borders() +\n  tm_layout(\n    legend.show = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    legend.width = 0.2,\n    legend.height = 0.5\n  )\n\npeak_weekend_evening_map\n\n\n\n\n\n\n\nCode\n# Creating a static map of peak weekend evening bus traffic\npeak_weekend_evening_map &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(bus_traffic_09) +\n  tm_fill(\n    col = \"peak_weekend_evening\",\n    palette = \"Blues\",\n    title = \"Peak Weekend Evening Traffic\",\n    id = \"loc_descriptions\",\n    showNA = FALSE,\n    alpha = 0.6,\n    breaks = c(0, 500, 1000, 2000, 3000, 5000, 10000, 50000, 100000, 300000, 550000)\n  ) +\n  tm_borders() +\n  tm_layout(legend.show = TRUE)\n\n# Display the map\npeak_weekend_evening_map\n\n\n\n\n\nUnsurprisingly, the weekdays’ trip volumes surpass that of the weekends/holidays, most plausibly due to the working crowd. Nonetheless, the areas regardless of the peak hour time frames, the areas which see higher human traffic remains unchanged, highlighting the efficacy of the Singapore bus network in serving the needs of the commuters.\n\n\n\nCode\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n# Function to create a scatter plot\ncreate_scatter_plot &lt;- function(data, y_column_name, title, color = \"blue\") {\n  ggplot(data, aes_string(x = \"total_busstops\", y = y_column_name)) +\n    geom_point(alpha = 0.7, color = color) +\n    ylim(0, 500000) +\n    scale_y_continuous(breaks = scales::pretty_breaks(n = 6)) +\n    labs(title = title, x = \"Number of Bus Stops\", y = \"\") +\n    theme(panel.grid = element_blank())  # Removed axis.text.y = element_blank()\n}\n\n# Creating individual scatter plots\nmorning_peak_weekday &lt;- create_scatter_plot(bus_traffic_09, \"peak_weekday_morning\", \"Weekday Morning Peak\", \"blue\")\nevening_peak_weekday &lt;- create_scatter_plot(bus_traffic_09, \"peak_weekday_evening\", \"Weekday Evening Peak\", \"blue\")\nmorning_peak_weekend &lt;- create_scatter_plot(bus_traffic_09, \"peak_weekend_morning\", \"Weekend/PH Morning Peak\", \"green\")\nevening_peak_weekend &lt;- create_scatter_plot(bus_traffic_09, \"peak_weekend_evening\", \"Weekend/PH Evening Peak\", \"green\")\n\n# Combining the plots using grid.arrange\ncombined_plot &lt;- grid.arrange(morning_peak_weekday, evening_peak_weekday, morning_peak_weekend, evening_peak_weekend, ncol = 2, nrow = 2)\n\n\n\n\n\nThe volume of passenger trips appears to be greatest in regions having 4 to 8 bus stops. Contrarily, areas with the most bus stops, ranging from 9 to 11, did not experience the highest levels of passenger traffic during any peak times.\n\nThis indicates the possibility of an ideal number of bus stops within each 500m-wide area that could help in alleviating congestion, measures taken could be to look into replanning bus stops placements so as to not have diminishing returns."
  },
  {
    "objectID": "Take-home_Ex1/Take-home_Ex1.html#local-indicators-of-spatial-association",
    "href": "Take-home_Ex1/Take-home_Ex1.html#local-indicators-of-spatial-association",
    "title": "Take-home_Ex1",
    "section": "6 Local Indicators of Spatial Association",
    "text": "6 Local Indicators of Spatial Association\nIn preparing for spatial autocorrelation analysis, we first establish a spatial weights matrix to map the interconnections between hexagonal spatial units by their distance. Key to this setup is ensuring that each unit has at least one, but not all, other units as neighbors to reflect diverse spatial relationships accurately.\nGiven our dataset’s skewed distribution, we’ve chosen to assign 10 neighbors per feature, exceeding the suggested minimum of eight. This approach enhances the robustness of our spatial connectivity analysis.\nOur study area, marked by unevenly distributed bus stops and zones with low residential or business density, leads us to prefer distance-based methods over contiguity-based ones. This choice aligns better with our data’s spatial characteristics.\nWe adopt the Adaptive Distance-Based method, with a fixed number of neighbors, to accommodate our dataset’s right-skewed distribution. This method ensures each hexagon connects with exactly 10 neighbors. We employ the st_knn function to identify neighbors and st_weights to create row-standardized spatial weights, setting a solid foundation for our spatial autocorrelation analysis.\n\n6.1 Global Spatial Association Globally with Global Moran’s I\n\n\nCode\n# Adjusting bus_traffic_09 data with spatial weights\nweightmat_all &lt;- bus_traffic_09 %&gt;%\n  mutate(\n    knn = st_knn(geometry, k = 10),  # Calculating 10 nearest neighbors\n    weight_type = st_weights(knn, style = 'W'),  # Generating weights\n    .before = 1  # Placing the new columns at the beginning\n  )\n\n\n# check the output\nkable(head(weightmat_all))\n\n\n\n\n\nknn\nweight_type\nhex_id\ntotal_busstops\nbusstop_ids\nloc_descriptions\npeak_weekday_morning\npeak_weekday_evening\npeak_weekend_morning\npeak_weekend_evening\ngeometry\n\n\n\n\n2, 4, 5, 8, 9, 12, 16, 22, 23, 38\n0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1\n34\n1\n25059\nAFT TUAS STH BLVD\n91\n348\n0\n96\nPOLYGON ((3970.122 27925.48...\n\n\n1, 4, 5, 8, 9, 12, 16, 22, 23, 38\n0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1\n65\n1\n25751\nBEF TUAS STH AVE 14\n41\n131\n38\n40\nPOLYGON ((4220.122 28358.49...\n\n\n5, 6, 9, 10, 13, 14, 16, 17, 24, 25\n0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1\n99\n1\n26379\nYONG NAM\n50\n278\n78\n84\nPOLYGON ((4470.122 30523.55...\n\n\n1, 2, 8, 9, 12, 16, 22, 23, 38, 39\n0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1\n127\n1\n25761\nOPP REC S'PORE\n129\n1689\n246\n454\nPOLYGON ((4720.122 28358.49...\n\n\n3, 6, 9, 10, 12, 13, 14, 16, 17, 24\n0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1\n129\n2\n25719, 26389\nTHE INDEX; BEF TUAS STH AVE 5\n1104\n2608\n503\n646\nPOLYGON ((4720.122 30090.54...\n\n\n3, 5, 7, 9, 10, 13, 14, 17, 18, 25\n0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1\n130\n1\n26369\nSEE HUP SENG\n34\n185\n117\n27\nPOLYGON ((4720.122 30956.57...\n\n\n\n\n\n\n\n\n\nCode\n# Ensure consistent results\nset.seed(5555)\n\n# Assuming 'bus_traffic_09' is a spatial dataset with a 'geometry' column\n# List of columns for peak traffic analysis\nbus_traffic_columns &lt;- c(\"peak_weekday_morning\", \"peak_weekday_evening\", \"peak_weekend_morning\", \"peak_weekend_evening\")\n\n# Function to calculate global Moran's I\ncalculate_moran_i &lt;- function(dataset, column_name, neighbors) {\n  # Validate that the dataset is properly structured as a spatial data frame\n  if (!(\"geometry\" %in% names(dataset))) {\n    stop(\"The dataset does not have a geometry column.\")\n  }\n\n  # Validate that the column_name exists in the dataset\n  if (!(column_name %in% names(dataset))) {\n    stop(paste(\"Column\", column_name, \"not found in the dataset.\"))\n  }\n\n  # Establishing spatial relationships\n  neighbors_list &lt;- st_knn(dataset$geometry, k = neighbors)\n  weights &lt;- st_weights(neighbors_list, style = 'W')\n\n  # Executing Moran's I calculation\n  moran_test_result &lt;- global_moran_perm(dataset[[column_name]], neighbors_list, weights, nsim = 99)\n  \n  # Organizing the output\n  output &lt;- list(\n    column = column_name,\n    moran_i = moran_test_result\n  )\n  \n  return(output)\n}\n\n# Running the Moran's I calculation for each traffic time slot\nmoran_i_results &lt;- lapply(bus_traffic_columns, function(column) calculate_moran_i(bus_traffic_09, column, 10))\n\n# Displaying the calculated results\nprint(moran_i_results)\n\n\n[[1]]\n[[1]]$column\n[1] \"peak_weekday_morning\"\n\n[[1]]$moran_i\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.21341, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n[[2]]\n[[2]]$column\n[1] \"peak_weekday_evening\"\n\n[[2]]$moran_i\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.061867, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n[[3]]\n[[3]]$column\n[1] \"peak_weekend_morning\"\n\n[[3]]$moran_i\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.15841, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n[[4]]\n[[4]]$column\n[1] \"peak_weekend_evening\"\n\n[[4]]$moran_i\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.11109, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nFor each of the four time slots, the p-values associated with the Global Moran’s I test are less than 0.05, indicating a rejection of the null hypothesis, which suggests randomness in spatial patterns.\n\nAdditionally, the positive values of the Moran’s I statistics imply a tendency towards clustering in the spatial distribution across all time intervals.\n\n\n6.2 LISA assessment\nInvestigating spatial patterns at a detailed level, we utilize the Local Moran’s I analysis to identify specific areas with strong or weak spatial associations. The methodology categorizes regions based on clustering types like high-high or low-low, revealing areas of similar or contrasting characteristics. We apply the local_moran function from the sfdep package for examining passenger trips at a hexagonal level, which calculates neighbors and weights automatically and uses simulated data for precision.\n\n\nCode\n# Create a function to perform local Moran's I analysis\nget_lisa &lt;- function(weightmat_all, bus_traffic_column, k) {\n  # Check if the bus_traffic_column is valid\n  if (nchar(bus_traffic_column) == 0) {\n    stop(\"The column name provided is empty.\")\n  }\n\n  # Compute spatial weights\n  nb &lt;- st_knn(weightmat_all$geometry, k = k)\n  wt &lt;- st_weights(nb, style = 'W')\n\n  # Perform local Moran's I analysis and create a new data frame\n  result &lt;- weightmat_all %&gt;% \n    mutate(\n      local_moran = local_moran(.data[[bus_traffic_column]], nb, wt, nsim = 99),\n      .before = 1\n    ) %&gt;%\n    unnest(local_moran)\n  \n  return(result)\n}\n\n# Assuming bus_traffic_columns is a vector of column names\nbus_traffic_columns &lt;- c(\"peak_weekday_morning\", \"peak_weekday_evening\", \"peak_weekend_morning\", \"peak_weekend_evening\")\n\n# Initialize a list to store results for each bus_traffic_column\nlisa_results &lt;- list()\n\n# Apply the function for each bus traffic time interval and store results in the list\nfor (btc in bus_traffic_columns) {\n  lisa_results[[btc]] &lt;- get_lisa(weightmat_all, btc, k = 10)\n  \n  # Remove columns that don't belong to the specific time interval\n  unwanted_columns &lt;- setdiff(bus_traffic_columns, btc)\n  lisa_results[[btc]] &lt;- lisa_results[[btc]][, !(names(lisa_results[[btc]]) %in% unwanted_columns)]\n}\n\n# Show sample output in an interactive table\ndatatable(lisa_results[[\"peak_weekday_morning\"]], \n          class = 'cell-border stripe', \n          options = list(pageLength = 5))\n\n\n\n\n\n\n\nWe now utilize the tmap package to generate choropleth maps that display Local Moran’s I values and corresponding p-values for four time intervals. The maps will highlight only significant Local Moran’s I values at a 5% significance level. The existing code is specifically used to extract these key Local Moran’s I values for map creation.\n\n\nCode\nget_sig_lmi_map &lt;- function(lisa_table, title) {\n  \n  sig_lisa_table &lt;- lisa_table %&gt;%\n    filter(p_ii_sim &lt; 0.05)\n  \n  result &lt;- tm_shape(lisa_table) +\n    tm_polygons() +\n    tm_borders(alpha = 0.5) +\n    tm_shape(sig_lisa_table) +\n    tm_fill(\"ii\", palette = \"Reds\") + \n    tm_borders(alpha = 0.4) +\n    tm_layout(\n      main.title = title,\n      main.title.size = 1.3\n    )\n  \n  return(result)\n  \n}\n# Applying the function to create maps for different peak intervals\n\nsig_lmi_1 &lt;- get_sig_lmi_map(lisa_results[[\"peak_weekday_morning\"]], \"Weekday Morning\" )\nsig_lmi_2 &lt;- get_sig_lmi_map(lisa_results[[\"peak_weekday_evening\"]], \"Weekday Afternoon\" )\nsig_lmi_3 &lt;- get_sig_lmi_map(lisa_results[[\"peak_weekend_morning\"]], \"Weekend Morning\" )\nsig_lmi_4 &lt;- get_sig_lmi_map(lisa_results[[\"peak_weekend_evening\"]], \"Weekend Afternoon\" )\n\ntmap_mode('plot')\n\ntmap_arrange(\n  sig_lmi_1,\n  sig_lmi_2,\n  sig_lmi_3,\n  sig_lmi_4,\n  asp = 2,\n  nrow = 2,\n  ncol = 2\n)\n\n\n\n\n\nNow we zoom into an analysis of which α = 5% for Local Indicators of Spatial Association (LISA)\n\n\nCode\n# Function for constructing thematic maps based on significant Local Moran's I data\ngenerate_thematic_lisa_maps &lt;- function(lisa_data_set, chart_title) {\n  \n  # Filtering for significant Local Moran's I values\n  significant_lisa_data &lt;- lisa_data_set %&gt;%\n    filter(p_ii_sim  &lt; 0.05)\n  \n  # Building the map visualization\n  thematic_map_output &lt;- tm_shape(lisa_data_set) +\n        tm_polygons(alpha = 0.5) +\n        tm_borders(alpha = 0.5) +\n        tm_shape(significant_lisa_data) +\n        tm_fill(\"median\",  \n                id = \"loc_desc\",  \n                palette = c(\"deepskyblue\", \"salmon\", \"green\", \"darkred\"),\n                alpha = 0.7) +\n        tm_borders(alpha = 0.4) +\n        tm_layout(\n            main.title = chart_title,\n            main.title.size = 1.5,\n            legend.position = c(\"left\", \"top\")\n        )\n\n    return(thematic_map_output)\n}\n\n# Creating maps for different time intervals\nlisa_map_morning_peak &lt;- generate_thematic_lisa_maps(lisa_results[[\"peak_weekday_morning\"]], \"Significant LISA - Weekday Morning\")\nlisa_map_evening_peak &lt;- generate_thematic_lisa_maps(lisa_results[[\"peak_weekday_evening\"]], \"Significant LISA - Weekday Evening\")\nlisa_map_weekend_morning &lt;- generate_thematic_lisa_maps(lisa_results[[\"peak_weekend_morning\"]], \"Significant LISA - Weekend Morning\")\nlisa_map_weekend_evening &lt;- generate_thematic_lisa_maps(lisa_results[[\"peak_weekend_evening\"]], \"Significant LISA - Weekend Evening\")\n\n\n\n\nCode\ntmap_mode('plot')\nlisa_map_morning_peak\n\n\n\n\n\n\n\nCode\ntmap_mode('plot')\nlisa_map_evening_peak\n\n\n\n\n\n\n\nCode\ntmap_mode('plot')\nlisa_map_weekend_morning\n\n\n\n\n\n\n\nCode\ntmap_mode('plot')\nlisa_map_weekend_evening\n\n\n\n\n\n\nDeep Sky Blue Areas (Low-Low Clusters): These zones are characterized by fewer trips at bus stops, which are also surrounded by other areas with low trip frequencies, forming a cluster of less busy locations.\nGreen Areas (Low-High Outliers): These areas show unique patterns where bus stops have fewer trips in contrast to neighboring areas, indicating isolated spots of lower activity amidst busier surroundings.\nSalmon Areas (High-Low Outliers): These regions are marked by bus stops with notably higher trip counts than their neighboring areas, highlighting them as exceptional spots of increased activity within less active zones.\nDark Red Areas (High-High Clusters): Here, bus stops see a higher volume of trips, and are in proximity to areas with similarly high activity, suggesting a concentration of busy locations.\n\n\n\n6.3 Findings\n\nHigh-High\n\nWeekday morning vs evening, generally see the high-high clusters in the same areas (Business Districts/ Residential areas, however it is noticed that the clusters generally shrink in size. which could be due to the following reasons:\n\nMorning Peak: Bus use spikes in the morning due to simultaneous commutes to work and schools, creating distinct high-usage clusters.\nEvening Spread: Evening could be seeing a staggered exodus from business hubs to varied locations, diffusing the earlier high-usage patterns.\nShift in Activities: Daytime high traffic in business and industrial zones transitions to residential and leisure areas at night, altering usage patterns.1.\nVaried Destinations: Evening trips are more dispersed as people head to homes, dining, or leisure spots, reducing reliance on main transit hubs.\nDiverse Evening Travel: With more unpredictable routes and choices for non-commuting travel in the evening, the uniform high-usage clusters dissipate.\n\nWeekend mornings see concentrated bus travel to areas busy with shopping and leisure, forming high-high clusters. By evening, these clusters diminish as daytime activities cease and the commuters might have returned home in a staggered fashion outside of the peak hours\n\n\n\nLow-Low\n\nBus trips are less frequent in the industrial western sectors of Singapore, indicating lower public transport usage, possibly due to a sparse population or alternative transport options. These patterns showcase the area’s distinct travel dynamics.\nComparing the maps for weekday mornings and evenings or weekend mornings and evenings, one may notice changes in the size and distribution of low-low clusters. These changes can provide insights into how public transportation demand varies throughout the day and week.\nNotably, you can see some areas such as Woodlands Waterfront Park and West Coast park see their Low-Low cluster shrinking during the weekday evening\nSimilar to the weekday, the low low clusters for the weekend are typically in the industrial areas in the west for both morning and evening"
  },
  {
    "objectID": "In-class_Ex5/In-class_Ex5.html",
    "href": "In-class_Ex5/In-class_Ex5.html",
    "title": "In-class_Ex5",
    "section": "",
    "text": "Code\ndevtools:: install_github(\"LukeCe/spflow\")\n\n\n\n\nCode\npacman::p_load(tmap, sf, spdep, sp, Matrix, spflow, reshape2, knitr, tidyverse)"
  },
  {
    "objectID": "In-class_Ex5/data/geospatial/MPSZ-2019.html",
    "href": "In-class_Ex5/data/geospatial/MPSZ-2019.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex5/data/geospatial/FinServ.html",
    "href": "In-class_Ex5/data/geospatial/FinServ.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "In-class_Ex5/data/geospatial/entertn.html",
    "href": "In-class_Ex5/data/geospatial/entertn.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1_Data_Wrangling_With_R.html",
    "href": "Hands-on_Ex1/Hands-on_Ex1_Data_Wrangling_With_R.html",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling",
    "section": "",
    "text": "In this hands-on exercise, the class learnt how to import and wrangle Geospatial data using the appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1_Data_Wrangling_With_R.html#overview",
    "href": "Hands-on_Ex1/Hands-on_Ex1_Data_Wrangling_With_R.html#overview",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling",
    "section": "",
    "text": "In this hands-on exercise, the class learnt how to import and wrangle Geospatial data using the appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1_Data_Wrangling_With_R.html#learning-outcomes",
    "href": "Hands-on_Ex1/Hands-on_Ex1_Data_Wrangling_With_R.html#learning-outcomes",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling",
    "section": "Learning Outcomes:",
    "text": "Learning Outcomes:\n\nInstall and load the sf and tidyverse packages in R.\nImport geospatial and non-geospatial data using appropriate functions.\nExplore and manipulate data frames using Base R and sf functions.\nAssign or transform coordinate systems using sf functions.\nConvert data into an sf data frame using the sf package.\nPerform geospatial operations using sf functions.\nConduct data wrangling tasks using the dplyr package.\nPerform Exploratory Data Analysis (EDA) using ggplot2 functions.”"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1_Data_Wrangling_With_R.html#getting-started",
    "href": "Hands-on_Ex1/Hands-on_Ex1_Data_Wrangling_With_R.html#getting-started",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling",
    "section": "Getting started",
    "text": "Getting started\nThe code chunk below install and load sf and tidyverse packages into R environment\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1_Data_Wrangling_With_R.html#importing-geospatial-data",
    "href": "Hands-on_Ex1/Hands-on_Ex1_Data_Wrangling_With_R.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling",
    "section": "Importing Geospatial Data:",
    "text": "Importing Geospatial Data:\n\nThe data used for the exercise are as follow:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb\n\n\n\nImporting feature data\nA utility known as st_read is used in the data import procedure. This function reads many map formats and extensions, including.shp,.dbf,.prj, and.shx. The following parameters are used by the function:\n\nThe dsn Parameter, specifies the location of which where we map our files.\nThe layer parameter in this section emphasizes specific map feature\nLastly, we note that extensions such as .shp, .dbf, .prj and .shx are not necessary.\n\n\nImporting polygon feature dataImporting Polylines feature dataImporting GIS feature data\n\n\n\nmpsz = st_read(dsn = \"data/geospatial\",layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Zackkoh94\\ISSS624\\Hands-on_Ex1\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nShapefiles are a common format for storing geospatial vector data, representing various geographic features like points, lines, and polygons. The “MP14_SUBZONE_WEB_PL” refers to a specific layer within a shapefile which contains polygon features. These polygons may represent subzones within a geographic region, such as those outlined in the Master Plan 2014 Subzone Boundary (Web) data.\nThe dataset serves as a forward-looking plan for Singapore’s development over the next 10 to 15 years, known as the Development Master Plan 2014. Subzones typically revolve around key focal points, like neighborhood centers or activity nodes, and a Planning Area can consist of more than 10 subzones. The data is sourced from the Singapore Government.\n\n\n\n\ncyclingpath &lt;- st_read(dsn = \"/Zackkoh94/ISSS624/Hands-on_Ex1/data/geospatial\", layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\Zackkoh94\\ISSS624\\Hands-on_Ex1\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\nThis code imports data representing polylines from a shapefile. Polylines are used to depict linear features like roads, rivers, or cycling paths, consisting of connected straight lines. In this instance, the data represents a cycling path within Singapore, excluding park connectors. The source of this data is the Land Transport Authority.\n\n\n\n\npreschool &lt;- st_read(dsn = \"/Zackkoh94/ISSS624/Hands-on_Ex1/data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\Zackkoh94\\ISSS624\\Hands-on_Ex1\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nThis code imports geospatial data in KML format, which is commonly used for annotating and visualizing geographic information on maps and Earth browsers. Specifically, it imports data about the locations of pre-schools in Singapore from a KML file. The source of this data is the Singapore Government."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1_Data_Wrangling_With_R.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex1/Hands-on_Ex1_Data_Wrangling_With_R.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling",
    "section": "Checking the Content of A Simple Feature Data Frame",
    "text": "Checking the Content of A Simple Feature Data Frame\nThe following codes are for retrieve information related to the content of a simple feature data frame:\n\nWorking with st_geometry()\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303..."
  },
  {
    "objectID": "In-class_Ex5/data/geospatial/Business.html",
    "href": "In-class_Ex5/data/geospatial/Business.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "In-class_Ex5/data/geospatial/F&B.html",
    "href": "In-class_Ex5/data/geospatial/F&B.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "In-class_Ex5/data/geospatial/Liesure&Recreation.html",
    "href": "In-class_Ex5/data/geospatial/Liesure&Recreation.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "In-class_Ex5/data/geospatial/Retails.html",
    "href": "In-class_Ex5/data/geospatial/Retails.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Applied Geospatial Analytics (ISSS624)",
    "section": "",
    "text": "Salutations,\nWelcome to ISSS624: Geospatial Analytics Applications. I am delighted to provide an insightful overview of my five-week educational journey in the realm of Geospatial Analytics, masterfully instructed by Professor Kam Tin Seong at Singapore Management University. For those seeking additional information regarding ISSS624, please peruse the dedicated journal section on this website.\nSincerely,\nZack"
  }
]